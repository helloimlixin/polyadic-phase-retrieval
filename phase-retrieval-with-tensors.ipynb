{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Computational Phase Retrieval with Tensor Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Device Information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tue Jul 13 10:47:18 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 165...  Off  | 00000000:01:00.0 Off |                  N/A |\n| N/A   48C    P8     8W /  N/A |    301MiB /  3911MiB |      5%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "source": [
    "## Import Required Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        print(\"Num GPUs Available: \", len(gpus))\n",
    "        for gpu in gpus:\n",
    "            # Allow memory growth for the GPU.\n",
    "            # Reference: https://www.tensorflow.org/guide/gpu\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized.\n",
    "        print(e)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rc, rcParams\n",
    "rcParams['font.family'] = 'Cubano'\n",
    "rc('text', usetex=False)\n",
    "\n",
    "import warnings"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 109,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow version: 2.5.0\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## GPU Benchmark\n",
    "\n",
    "Reference: https://www.tensorflow.org/guide/gpu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elapsed time with TensorFlow GPU: 0.5627357959747314\n",
      "Elapsed time with Numpy: 15.692136526107788\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "n = 5000\n",
    "num_iters = 10\n",
    "\n",
    "'''\n",
    "Test with TensorFlow GPU.\n",
    "'''\n",
    "start_tf = time.time()\n",
    "\n",
    "for i in range(num_iters):\n",
    "    # Tensors are defaultly placed on the GPU (CPU would be considerably slower due\n",
    "    # to the incurred communication cost).\n",
    "    # with tf.device('/CPU:0'):\n",
    "    a = tf.ones((n, n))\n",
    "    b = tf.ones((n, n))\n",
    "\n",
    "    # Run on the GPU\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "print(f'Elapsed time with TensorFlow GPU: {time.time() - start_tf}')\n",
    "\n",
    "'''\n",
    "Test with Numpy.\n",
    "'''\n",
    "start_np = time.time()\n",
    "\n",
    "# for i in range(num_iters):\n",
    "#     a = np.ones((n, n))\n",
    "#     b = np.ones((n, n))\n",
    "\n",
    "#     c = np.dot(a, b)\n",
    "\n",
    "print(f'Elapsed time with Numpy: {time.time() - start_np}') # CAN BE SLOW\n"
   ]
  },
  {
   "source": [
    "## Low Rank Phase Retrieval\n",
    "\n",
    "References:\n",
    "\n",
    "\\[1\\] Namrata Vaswani, Seyedehsara Nayer, Yonina C. Eldar. *Low Rank Phase Retrieval*. https://rutgers.box.com/s/dntl0sh157p62rgi1zerdaxrqthugr32\n",
    "\n",
    "\\[2\\] Namrata Vaswani. *Nonconvex Structured Phase Retrieval*. https://rutgers.box.com/s/x02w8frd1ep01cxdjlnojufa9npvstsz.\n",
    "\n",
    "\\[3\\] Tamara G. Kolda, Brett W. Bader. *Tensor Decompositions and Applications*. https://rutgers.box.com/s/aq9psx3mgwhms6rrzlhn94h56c3oshox. \n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Define Data Directories"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = './videos/' # directory of the test videos\n",
    "OUTPUT_DIR = './output/' # output directory\n",
    "FRAMES_DIR = './ouput/frames/' # output directory of the extracted video frames "
   ]
  },
  {
   "source": [
    "### Load the Test Video"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Directory already exists!\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-0.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-1.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-2.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-3.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-4.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-5.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-6.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-7.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-8.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-9.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-10.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-11.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-12.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-13.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-14.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-15.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-16.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-17.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-18.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-19.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-20.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-21.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-22.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-23.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-24.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-25.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-26.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-27.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-28.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-29.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-30.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-31.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-32.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-33.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-34.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-35.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-36.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-37.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-38.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-39.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-40.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-41.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-42.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-43.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-44.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-45.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-46.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-47.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-48.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-49.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-50.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-51.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-52.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-53.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-54.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-55.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-56.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-57.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-58.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-59.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-60.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-61.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-62.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-63.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-64.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-65.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-66.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-67.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-68.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-69.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-70.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-71.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-72.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-73.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-74.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-75.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-76.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-77.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-78.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-79.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-80.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-81.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-82.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-83.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-84.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-85.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-86.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-87.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-88.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-89.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-90.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-91.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-92.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-93.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-94.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-95.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-96.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-97.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-98.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-99.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-100.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-101.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-102.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-103.jpg\n",
      "DEBUG: Captured..../ouput/frames/sara/frame-104.jpg\n",
      "Cannot receive frame (probably end of stream). Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Read the video.\n",
    "video_path = INPUT_DIR + os.listdir(INPUT_DIR)[0] # define video path\n",
    "cap = cv2.VideoCapture(video_path) # read the video from path\n",
    "video_name = os.listdir(INPUT_DIR)[0].split('.')[0] # get the name of the video\n",
    "\n",
    "# Creat the folder to store the extracted frames of the video.\n",
    "try:\n",
    "    if not os.path.exists(FRAMES_DIR + video_name):\n",
    "        os.makedirs(FRAMES_DIR + video_name)\n",
    "    else:\n",
    "        print('Directory already exists!')\n",
    "except OSError:\n",
    "    print('OS ERROR')\n",
    "\n",
    "k = 0 # frame number, k = 0, 1, 2, ..., q - 1\n",
    "Xlist = []\n",
    "while (True):\n",
    "    # Capture the video frame-by-frame.\n",
    "    # Code adopted: https://docs.opencv.org/3.4/dd/d43\n",
    "    # # tutorial_py_video_display.html\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If the frame is read correctly the return boolean (ret) is true.\n",
    "    if not ret:\n",
    "        print(\"Cannot receive frame (probably end of stream). Exiting...\")\n",
    "        break\n",
    "    else:\n",
    "        # Convert the frame to grayscale.\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        name = FRAMES_DIR + video_name + '/frame-' + str(k) + '.jpg'\n",
    "        print('DEBUG: Captured...' + name)\n",
    "        cv2.imwrite(name, gray_frame)\n",
    "        Xlist.append(gray_frame)\n",
    "\n",
    "        k += 1\n",
    "\n",
    "# Release the capture when finished.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "### Create the true signal tensor.\n",
    "\n",
    "Tensors are multi-dimensional arrays with a uniform type (`dtype`). All tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one.\n",
    "\n",
    "**Note**: In libraries like tensorflow, the rank of the tensor actually denotes the order of the tensor in our convention. We call the `rank` of a tensor in a similar manner as the rank of a matrix.\n",
    "\n",
    "The gray-scaled signal is modeled as a three-ordered tensor $\\boldsymbol{\\mathcal{X}} \\in \\mathbb{R}^{I_1 \\times I_2 \\times q}$, where $I_1 \\times I_2$ correspond to the pixel coordinates within each frame and $q$ is the total number of frames captured.\n",
    "\n",
    "**Signal Dimension**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The dimension of the true signal tensor: I1 x I2 x q: 480 x 640 x 105\n"
     ]
    }
   ],
   "source": [
    "Xast = tf.constant(Xlist, tf.double)\n",
    "q, I1, I2 = Xast.shape\n",
    "print(f'The dimension of the true signal tensor: I1 x I2 x q: {I1} x {I2} x {q}')"
   ]
  },
  {
   "source": [
    "### Generate Phaseless Measurements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = [] # measurement tensor in list format\n",
    "m = 10 # number of measurements\n",
    "\n",
    "np.random.seed(5) # set random seed\n",
    "\n",
    "# Generate i.i.d. measurement tensors.\n",
    "for j in range(m):\n",
    "    Aj = []\n",
    "    for k in range(q):\n",
    "        Ajk = np.random.randn(I1, I2) # i.i.d. normal measurement\n",
    "        Aj.append(Ajk)\n",
    "    A.append(Aj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate phaseless measurements.\n",
    "Y = np.zeros((m, q)) # matrix of the phaseless measurements\n",
    "\n",
    "for j in range(m):\n",
    "    for k in range(q):\n",
    "        Y[j, k] = tf.tensordot(A[j][k], Xast[k], axes=([0, 1], [0, 1]))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DEBUG\n\nDimension of the phaseless measurement matrix: m x q: 10 x 105\n\nPhaseless Measurements:\n\n [[1.27160654e+08 1.09215703e+10 1.05717725e+10 ... 1.08445766e+10\n  1.71644657e+08 6.02085249e+07]\n [4.58334424e+09 4.13127136e+08 1.12115112e+08 ... 1.56249743e+09\n  3.07167905e+06 2.64488749e+09]\n [1.61810815e+09 7.29115357e+08 8.63181443e+09 ... 1.63338103e+09\n  4.72147160e+08 4.21422069e+06]\n ...\n [9.36276208e+09 2.34494775e+07 5.31417782e+09 ... 8.60596714e+07\n  2.24366966e+10 9.15723194e+09]\n [3.98034489e+09 2.67960132e+08 1.04974115e+10 ... 9.55799810e+08\n  1.46223399e+09 2.42790383e+09]\n [6.47884266e+06 3.99879918e+09 3.52638316e+09 ... 5.97114690e+08\n  1.24974284e+09 1.25169085e+09]]\n"
     ]
    }
   ],
   "source": [
    "print('DEBUG')\n",
    "print(f'\\nDimension of the phaseless measurement matrix: m x q: {Y.shape[0]} x {Y.shape[1]}\\n')\n",
    "print('Phaseless Measurements:\\n\\n', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(I1, I2, q, R):\n",
    "    U1 = np.random.randn(I1, rank)\n",
    "    U2 = np.random.randn(I2, rank)\n",
    "    U = [U1,U2]\n",
    "    B = np.random.randn(rank, q)\n",
    "\n",
    "    return U, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal(U, B, R, Lambda=None, type='CP'):\n",
    "    \"\"\"Construct Tensor from Kruskal Formulation.\n",
    "\n",
    "        Args:\n",
    "            U: list consisting of two factor matrices U1 (I1 x R)\n",
    "                and U2 (I2 x R) for the three-way case.\n",
    "            B: the B (q x R) factor matrix.\n",
    "            R: assumped rank (a scalar) of the low-rank tensor.\n",
    "            Lambda: normalization factors (length R).\n",
    "        \n",
    "        Returns:\n",
    "            Xhat: signal estimate (I1 x I2 x q).\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    if type == 'CP':\n",
    "        U1, U2 = U[0], U[1]\n",
    "        I1, I2, q = U1.shape[0], U2.shape[0], B.shape[0]\n",
    "        Xhat = tf.zeros([I1, I2, q])\n",
    "        if Lambda is None:\n",
    "            Lambda = tf.ones([R,])\n",
    "        for r in range(R):\n",
    "            U1U2 = tf.tensordot(U1[:, r], U2[:, r], axes=0)\n",
    "            Xhat += Lambda[r] * tf.tensordot(U1U2, B[:, r], axes=0)\n",
    "        \n",
    "        return Xhat\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DEBUG | Mean squared error for reconstruction: 2.1168126806969667e-07\n"
     ]
    }
   ],
   "source": [
    "from tensorly.decomposition import parafac\n",
    "\n",
    "X = tl.tensor(np.arange(24).reshape((3, 4, 2)), dtype=tl.float32)\n",
    "weights, factors = parafac(X, rank=3)\n",
    "\n",
    "X_test = kruskal([factors[0], factors[1]], factors[2], 3, weights)\n",
    "\n",
    "err = X - X_test\n",
    "\n",
    "print(f'DEBUG | Mean squared error for reconstruction: {tf.math.reduce_sum(tf.multiply(err, err)).numpy()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent(U, B, A, Y, R, max_iter):\n",
    "    Xhat = kruskal(U, B, R)\n",
    "    for _ in range(max_iter):\n",
    "        for k in range(q):\n",
    "            Ax = []\n",
    "            for j in range(m):\n",
    "                Ax.append(tf.tensordot(A[j][k], X_ast[k], axes=([0, 1], [0, 1])))\n",
    "            Ck = tf.linalg.diag(tf.angle(Ax))\n",
    "            U[0] = least_squares_solver()\n",
    "    \n",
    "    return U, Xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_lrpr(A, Y, rank=10, max_iter=5):\n",
    "    U, B = initialize(I1, I2, q, R)\n",
    "    \n",
    "    return descent(U, B, A, Y, R, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorLRPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorUtils"
   ]
  }
 ]
}