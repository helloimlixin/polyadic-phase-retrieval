{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Computational Phase Retrieval with Tensor Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Device Information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sun Jul 18 17:21:55 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 165...  Off  | 00000000:01:00.0 Off |                  N/A |\n| N/A   52C    P8     6W /  N/A |    344MiB /  3911MiB |     20%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "source": [
    "## Import Required Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        print(\"Num GPUs Available: \", len(gpus))\n",
    "        for gpu in gpus:\n",
    "            # Allow memory growth for the GPU.\n",
    "            # Reference: https://www.tensorflow.org/guide/gpu\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized.\n",
    "        print(e)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "tl.set_backend('tensorflow')\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rc, rcParams\n",
    "rcParams['font.family'] = 'Cubano'\n",
    "rc('text', usetex=False)\n",
    "\n",
    "import warnings\n",
    "from numba import jit, njit, prange\n",
    "from scipy.optimize import minimize\n",
    "import functools\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow version: 2.5.0\nNum GPUs Available:  1\n1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## GPU Benchmark\n",
    "\n",
    "Run preliminarily to avoid cold-start.\n",
    "\n",
    "Reference: https://www.tensorflow.org/guide/gpu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elapsed time with TensorFlow GPU: 0.0034453868865966797\n",
      "Elapsed time with Numpy: 0.26870226860046387\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "n = 1000\n",
    "num_iters = 10\n",
    "\n",
    "'''\n",
    "Test with TensorFlow GPU.\n",
    "'''\n",
    "start_tf = time.time()\n",
    "\n",
    "for i in range(num_iters):\n",
    "    # Tensors are defaultly placed on the GPU (CPU would be considerably \n",
    "    # slower due to the incurred communication cost).\n",
    "    a = tf.ones((n, n))\n",
    "    b = tf.ones((n, n))\n",
    "\n",
    "    # Run on the GPU\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "print(f'Elapsed time with TensorFlow GPU: {time.time() - start_tf}')\n",
    "\n",
    "'''\n",
    "Test with Numpy.\n",
    "'''\n",
    "start_np = time.time()\n",
    "\n",
    "for i in range(num_iters):\n",
    "    a = np.ones((n, n))\n",
    "    b = np.ones((n, n))\n",
    "\n",
    "    c = np.dot(a, b)\n",
    "\n",
    "print(f'Elapsed time with Numpy: {time.time() - start_np}') # CAN BE SLOW\n"
   ]
  },
  {
   "source": [
    "## Low Rank Phase Retrieval\n",
    "\n",
    "References:\n",
    "\n",
    "\\[1\\] Namrata Vaswani, Seyedehsara Nayer, Yonina C. Eldar. *Low Rank Phase Retrieval*. https://rutgers.box.com/s/dntl0sh157p62rgi1zerdaxrqthugr32\n",
    "\n",
    "\\[2\\] Namrata Vaswani. *Nonconvex Structured Phase Retrieval*. https://rutgers.box.com/s/x02w8frd1ep01cxdjlnojufa9npvstsz.\n",
    "\n",
    "\\[3\\] Tamara G. Kolda, Brett W. Bader. *Tensor Decompositions and Applications*. https://rutgers.box.com/s/aq9psx3mgwhms6rrzlhn94h56c3oshox. \n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Define Data Directories"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = './videos/' # directory of the test videos\n",
    "OUTPUT_DIR = './output/' # output directory\n",
    "FRAMES_DIR = './ouput/frames/' # output directory of the extracted video frames "
   ]
  },
  {
   "source": [
    "### Load the Test Video"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Directory already exists!\nDEBUG: Captured..../ouput/frames/sara/frame-0.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-1.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-2.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-3.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-4.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-5.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-6.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-7.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-8.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-9.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-10.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-11.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-12.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-13.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-14.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-15.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-16.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-17.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-18.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-19.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-20.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-21.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-22.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-23.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-24.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-25.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-26.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-27.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-28.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-29.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-30.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-31.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-32.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-33.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-34.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-35.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-36.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-37.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-38.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-39.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-40.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-41.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-42.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-43.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-44.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-45.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-46.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-47.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-48.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-49.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-50.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-51.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-52.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-53.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-54.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-55.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-56.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-57.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-58.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-59.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-60.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-61.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-62.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-63.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-64.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-65.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-66.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-67.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-68.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-69.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-70.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-71.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-72.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-73.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-74.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-75.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-76.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-77.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-78.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-79.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-80.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-81.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-82.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-83.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-84.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-85.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-86.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-87.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-88.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-89.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-90.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-91.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-92.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-93.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-94.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-95.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-96.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-97.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-98.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-99.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-100.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-101.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-102.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-103.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-104.jpg\nCannot receive frame (probably end of stream). Exiting...\nApproximate rank of each frame:  3\n"
     ]
    }
   ],
   "source": [
    "# Read the video.\n",
    "video_path = INPUT_DIR + os.listdir(INPUT_DIR)[0] # define video path\n",
    "cap = cv2.VideoCapture(video_path) # read the video from path\n",
    "video_name = os.listdir(INPUT_DIR)[0].split('.')[0] # get the name of the video\n",
    "\n",
    "# Creat the folder to store the extracted frames of the video.\n",
    "try:\n",
    "    if not os.path.exists(FRAMES_DIR + video_name):\n",
    "        os.makedirs(FRAMES_DIR + video_name)\n",
    "    else:\n",
    "        print('Directory already exists!')\n",
    "except OSError:\n",
    "    print('OS ERROR')\n",
    "\n",
    "k = 0 # frame number, k = 0, 1, 2, ..., q - 1\n",
    "Xlist = []\n",
    "Rhat = 0\n",
    "while (True):\n",
    "    # Capture the video frame-by-frame.\n",
    "    # Code adopted: https://docs.opencv.org/3.4/dd/d43\n",
    "    # tutorial_py_video_display.html\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If the frame is read correctly the return boolean (ret) is true.\n",
    "    if not ret:\n",
    "        print(\"Cannot receive frame (probably end of stream). Exiting...\")\n",
    "        break\n",
    "    else:\n",
    "        # Convert the frame to grayscale.\n",
    "        gray_frame_original = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        scale = 0.025\n",
    "        width = int(gray_frame_original.shape[1] * scale)\n",
    "        height = int(gray_frame_original.shape[0] * scale)\n",
    "        gray_frame = cv2.resize(gray_frame_original, (width, height))\n",
    "        name = FRAMES_DIR + video_name + '/frame-' + str(k) + '.jpg'\n",
    "        print('DEBUG: Captured...' + name)\n",
    "        svds = np.linalg.svd(gray_frame)[1]\n",
    "        max_svd, min_svd = np.max(svds), np.min(svds)\n",
    "        normalized_svds = svds / (max_svd - min_svd)\n",
    "        Rhat += np.sum(normalized_svds > 0.1)\n",
    "        cv2.imwrite(name, gray_frame)\n",
    "\n",
    "        # plt.plot(range(480), normalized_svds)\n",
    "        # plt.show()\n",
    "        \n",
    "        Xlist.append(gray_frame)\n",
    "\n",
    "        k += 1\n",
    "Rhat = Rhat // k + 1\n",
    "print('Approximate rank of each frame: ', Rhat)\n",
    "\n",
    "# Release the capture when finished.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "### Create the true signal tensor.\n",
    "\n",
    "Tensors are multi-dimensional arrays with a uniform type (`dtype`). All tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one.\n",
    "\n",
    "**Note**: In libraries like tensorflow, the rank of the tensor actually denotes the order of the tensor in our convention. We call the `rank` of a tensor in a similar manner as the rank of a matrix.\n",
    "\n",
    "The gray-scaled signal is modeled as a three-ordered tensor $\\boldsymbol{\\mathcal{X}} \\in \\mathbb{R}^{I_1 \\times I_2 \\times q}$, where $I_1 \\times I_2$ correspond to the pixel coordinates within each frame and $q$ is the total number of frames captured.\n",
    "\n",
    "**Signal Dimension**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The dimension of the true signal tensor: I1 x I2 x q: 12 x 16 x 10\nSample complexity for rank 3: O(114)\n"
     ]
    }
   ],
   "source": [
    "Xast = tf.constant(Xlist[:10], tf.float32)\n",
    "q, I1, I2 = Xast.shape\n",
    "Xast = tf.reshape(Xast, [I1, I2, q])\n",
    "print(f'The dimension of the true signal tensor: I1 x I2 x q: {I1} x {I2} x {q}')\n",
    "print(f'Sample complexity for rank {Rhat}: O({(q + I1 + I2) * Rhat})')"
   ]
  },
  {
   "source": [
    "### Generate Phaseless Measurements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_zeros(dim):\n",
    "    initializer = tf.zeros_initializer()\n",
    "    return tf.Variable(initializer(shape=dim, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elapsed time: 0.8982784748077393 seconds.\n"
     ]
    }
   ],
   "source": [
    "def generate_measurements(m, I1, I2, q):\n",
    "    A = initialize_zeros([m, I1, I2, q]) # measurement tensor\n",
    "\n",
    "    # Generate i.i.d. measurement tensors.\n",
    "    for j in range(m):\n",
    "        for k in range(q):\n",
    "            # i.i.d. normal measurements from the independent number stream\n",
    "            A[j,:,:,k].assign(tf.random.normal([I1, I2]))\n",
    "    \n",
    "    return A\n",
    "\n",
    "start = time.time()\n",
    "m = 200\n",
    "A = generate_measurements(m, I1, I2, q)\n",
    "print(f'Elapsed time: {time.time() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(200, 10)\n"
     ]
    }
   ],
   "source": [
    "# Generate phaseless measurements.\n",
    "Ylist = []\n",
    "for k in range(q):\n",
    "    # Normalize the true signal tensor with Frobenius norm.\n",
    "    normalized_Xast = tf.linalg.normalize(Xast[:,:,k], ord='fro', axis=[0, 1])[0]\n",
    "    Ylist.append(tf.tensordot(A[:,:,:,k], normalized_Xast, axes=([1, 2], [0, 1])))\n",
    "\n",
    "Y = tf.reshape(tf.convert_to_tensor(Ylist), [m, q])\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DEBUG\n\nDimension of the phaseless measurement matrix: m x q: 200 x 10\n\nPhaseless Measurements:\n\n tf.Tensor(\n[[ 1.4173288   1.1490718   1.5035605  ... -0.0121095   0.15729125\n  -1.039565  ]\n [-1.3361698  -0.22994685 -0.9057626  ... -0.38736638  0.618703\n  -1.079539  ]\n [-1.4741212   2.2361112  -1.6096847  ...  0.92064166 -0.554445\n  -1.8307835 ]\n ...\n [ 0.55836916  1.3080856  -1.2448782  ... -0.727911   -0.51140565\n  -0.14848077]\n [-1.3519084  -1.7848707  -0.85040784 ... -0.11440651 -0.5337188\n  -2.1890652 ]\n [-0.2648867   0.65368617 -0.52293766 ... -0.22146395 -0.5521327\n   1.1964184 ]], shape=(200, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('DEBUG')\n",
    "print(f'\\nDimension of the phaseless measurement matrix: m x q: {Y.shape[0]} x {Y.shape[1]}\\n')\n",
    "print('Phaseless Measurements:\\n\\n', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(I1, I2, q, R):\n",
    "    \"\"\"Initialize factor matrices.\"\"\"\n",
    "\n",
    "    U1 = tf.Variable(tf.random.normal([I1, R]))\n",
    "    U2 = tf.Variable(tf.random.normal([I2, R]))\n",
    "    B = tf.Variable(tf.random.normal([q, R]))\n",
    "\n",
    "    return [U1, U2], B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal(U, B, R, Lambda=None, type='CP'):\n",
    "    \"\"\"Construct Tensor from Kruskal Formulation.\n",
    "\n",
    "        Args:\n",
    "            U: list consisting of two factor matrices U1 (I1 x R)\n",
    "                and U2 (I2 x R) for the three-way case.\n",
    "            B: the B (q x R) factor matrix.\n",
    "            R: assumped rank (a scalar) of the low-rank tensor.\n",
    "            Lambda: normalization factors (length R).\n",
    "        \n",
    "        Returns:\n",
    "            Xhat: signal estimate (I1 x I2 x q).\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    # B = tf.cast(B, tf.float32)\n",
    "    if type == 'CP':\n",
    "        U1, U2 = U[0], U[1]\n",
    "        I1, I2, q = U1.shape[0], U2.shape[0], B.shape[0]\n",
    "        Xhat = tf.zeros([I1, I2, q])\n",
    "        if Lambda is None:\n",
    "            Lambda = tf.ones([R,])\n",
    "        for r in range(R):\n",
    "            U1U2 = tf.tensordot(U1[:, r], U2[:, r], axes=0)\n",
    "            Xhat += Lambda[r] * tf.tensordot(U1U2, B[:, r], axes=0)\n",
    "        \n",
    "        return Xhat\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DEBUG | MSE for reconstruction:  3.6551285e-08\n"
     ]
    }
   ],
   "source": [
    "def test_kruskal():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "    from tensorly.decomposition import parafac\n",
    "\n",
    "    X = tl.tensor(np.arange(24).reshape((3, 4, 2)), dtype=tl.float32)\n",
    "    test_rank = 4\n",
    "    weights, factors = parafac(X, rank=test_rank)\n",
    "\n",
    "    X_test = kruskal([factors[0], factors[1]], factors[2], test_rank, weights)\n",
    "\n",
    "    err = X - X_test\n",
    "\n",
    "    print('DEBUG | MSE for reconstruction: ', tf.math.reduce_sum(\n",
    "        tf.multiply(err, err)).numpy())\n",
    "\n",
    "test_kruskal() # test Kruskal tensor constructor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_error(Xast, U, B, R=10):\n",
    "    err = Xast - kruskal(U, B, R)\n",
    "\n",
    "    return tf.math.reduce_sum(tf.multiply(err, err)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent(Uhat, Bhat, A, Y, R, max_iter):\n",
    "    U1, U2 = Uhat[0], Uhat[1]\n",
    "    I1, I2 = U1.shape[0], U2.shape[0]\n",
    "    m = A.shape[0]\n",
    "    q = Bhat.shape[0]\n",
    "\n",
    "    @tf.function\n",
    "    def solve_U1():\n",
    "        \"\"\"Helper function to solve the least squares \n",
    "            problem for factor matrix U1.\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        m, I1, I2, q = A.shape\n",
    "        R = Bhat.shape[1]\n",
    "        vec_U1 = tf.reshape(U1, [I1 * R,])\n",
    "\n",
    "        for k in range(q):\n",
    "            yk = Y[:,k] # for linear projections\n",
    "            Ak = A[:,:,:,k]\n",
    "            bk = tf.reshape(Bhat[k,:], [1, R])\n",
    "\n",
    "            # dim bk khatri_rao U2: R x I2\n",
    "            U2B_kr = tf.transpose(tl.tenalg.khatri_rao([bk, U2]))\n",
    "            A_kr = tl.tenalg.mode_dot(Ak, U2B_kr, 2)\n",
    "            mat_A_kr = tf.reshape(A_kr, [m, I1 * R])\n",
    "            \n",
    "            yhat = tf.linalg.matvec(mat_A_kr, vec_U1)\n",
    "\n",
    "            loss += (1 / m) * tf.math.reduce_sum(tf.square(yhat - yk))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def solve_U2():\n",
    "        \"\"\"Helper function to solve the least squares \n",
    "            problem for factor matrix U2.\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        m, I1, I2, q = A.shape\n",
    "        R = Bhat.shape[1]\n",
    "\n",
    "        vec_U2 = tf.reshape(U2, [I2 * R,])\n",
    "\n",
    "        for k in range(q):\n",
    "            yk = Y[:,k] # for linear projections\n",
    "            Ak = tf.reshape(A[:,:,:,k], [m, I2, I1])\n",
    "            bk = tf.reshape(Bhat[k,:], [1, R])\n",
    "\n",
    "            # dim bk khatri_rao U1: R x I1\n",
    "            U1B_KR = tf.transpose(tl.tenalg.khatri_rao([bk, U1]))\n",
    "            A_kr = tl.tenalg.mode_dot(Ak, U1B_KR, 2)\n",
    "            mat_A_kr = tf.reshape(A_kr, [m, I2 * R])\n",
    "\n",
    "            yhat = tf.linalg.matvec(mat_A_kr, vec_U2)\n",
    "            \n",
    "            loss += (1 / m) * tf.math.reduce_sum(tf.square(yhat - yk))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    '''\n",
    "    Perform optimizations.\n",
    "    '''\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.5, amsgrad=True)\n",
    "    opt_iters = 100\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        print(f'Iteration-{t}')\n",
    "        print('Computing....')\n",
    "        Xhat = kruskal(Uhat, Bhat, R)\n",
    "        Cy = np.zeros([m, q]).astype('float32')\n",
    "\n",
    "        '''\n",
    "        Update Phase (for complex measurements only).\n",
    "        '''\n",
    "        # for k in range(q):\n",
    "        #     AX = tf.tensordot(\n",
    "        #         A[:,:,:,k], Xhat[:,:,k], axes=([1, 2], [0, 1]))\n",
    "        #     Ck = tf.linalg.diag(tf.math.angle(AX))\n",
    "        #     Cy[:, k] = tf.linalg.matvec(Ck, Y[:,k])\n",
    "        \n",
    "        # opt = tf.keras.optimizers.SGD(0.1)\n",
    "        '''\n",
    "        Solve for U1.\n",
    "        '''\n",
    "        for _ in range(opt_iters):\n",
    "            opt.minimize(solve_U1, var_list=[U1])\n",
    "        \n",
    "        print('U1 optimized')\n",
    "        # opt.minimize(solve_U1, var_list=[U1],tape=tf.GradientTape())\n",
    "\n",
    "        '''\n",
    "        Solve for U2.\n",
    "        '''\n",
    "        for _ in range(opt_iters):\n",
    "            opt.minimize(solve_U2, var_list=[U2])\n",
    "        \n",
    "        print('U2 optimized')\n",
    "        # opt.minimize(solve_U2, var_list=[U2],tape=tf.GradientTape())\n",
    "\n",
    "        '''\n",
    "        Solve for bk's.\n",
    "        '''\n",
    "        # def solve_B(q):\n",
    "        #     least_squares_bks = []\n",
    "\n",
    "        #     for i in range(q):\n",
    "        #         @tf.function\n",
    "        #         def solve_bk\n",
    "        # vector = np.zeros((R,)).astype('float32')\n",
    "        # rhs = tf.reduce_sum(Cy)\n",
    "        # for k in range(q):\n",
    "        #     bk = Bhat[k,:]\n",
    "        #     U2U1_kr =  tl.tenalg.khatri_rao([U2, U1]) # khatri-rao product\n",
    "        #     # for j in range(m):\n",
    "        #     #     A3 = tf.reshape(A[j,:,:,k], [I1 * I2,])\n",
    "        #     #     rhs += Cy[j, k]\n",
    "        #     Ak = tf.reshape(A[:,:,:,k], [m, I1 * I2])\n",
    "        #     vector += tf.math.reduce_sum(\n",
    "        #         tf.linalg.matmul(Ak, U2U1_kr), axis=0)\n",
    "\n",
    "        #     Bhat[k,:] = tf.multiply(vector, tf.math.reciprocal(rhs))\n",
    "        \n",
    "        # print(\n",
    "        #     f'Reconstruction error: {reconstruct_error([U1, U2], Bhat, R):.2f}.')\n",
    "    \n",
    "    # Uhat = [U1, U2]\n",
    "    \n",
    "    return Uhat, Bhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plrpr(A, Y, R=5, max_iter=1):\n",
    "    \"\"\"Polyadic Low Rank Phase Retrieval.\n",
    "    \"\"\"\n",
    "    Uinit, Binit = initialize(I1, I2, q, R)\n",
    "    \n",
    "    Uhat, Bhat = descent(Uinit, Binit, A, Y, R, max_iter)\n",
    "\n",
    "    Xhat = kruskal(Uhat, Bhat, R)\n",
    "    \n",
    "    return Xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration-0\n",
      "Computing....\n",
      "U1 optimized\n",
      "U2 optimized\n",
      "DEBUG | Mean squared error for reconstruction: 21033890.0\n"
     ]
    }
   ],
   "source": [
    "def test_plrpr(A, Y, Xast, R=10, max_iter=10):\n",
    "    Xhat = plrpr(A, Y, R, max_iter)\n",
    "    filename = FRAMES_DIR + video_name + '/frame-reconstructed-0' + '.jpg'\n",
    "    cv2.imwrite(filename, Xhat[:,:,0].numpy())\n",
    "    err = Xast - Xhat\n",
    "\n",
    "    MSE = tf.math.reduce_sum(tf.multiply(err, err)).numpy()\n",
    "\n",
    "    print(f'DEBUG | Mean squared error for reconstruction: {MSE}')\n",
    "\n",
    "test_plrpr(A, Y, Xast, R = 10, max_iter = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-80ab800cc55c>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-80ab800cc55c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class TensorLRPR\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class TensorLRPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorUtils"
   ]
  },
  {
   "source": [
    "- Initialization (Spectral, HOSVD) for CP formulation.\n",
    "- Complex measurements.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}