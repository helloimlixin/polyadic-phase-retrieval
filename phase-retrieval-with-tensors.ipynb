{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Computational Phase Retrieval with Tensor Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Device Information"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wed Jul 14 16:18:24 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 165...  Off  | 00000000:01:00.0 Off |                  N/A |\n| N/A   41C    P8     4W /  N/A |    312MiB /  3911MiB |     10%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "source": [
    "## Import Required Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import tensorflow as tf\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        print(\"Num GPUs Available: \", len(gpus))\n",
    "        for gpu in gpus:\n",
    "            # Allow memory growth for the GPU.\n",
    "            # Reference: https://www.tensorflow.org/guide/gpu\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized.\n",
    "        print(e)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rc, rcParams\n",
    "rcParams['font.family'] = 'Cubano'\n",
    "rc('text', usetex=False)\n",
    "\n",
    "import warnings"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow version: 2.5.0\n",
      "Num GPUs Available:  1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## GPU Benchmark\n",
    "\n",
    "Run preliminarily to avoid cold-start.\n",
    "\n",
    "Reference: https://www.tensorflow.org/guide/gpu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elapsed time with TensorFlow GPU: 0.5779464244842529\nElapsed time with Numpy: 3.266334533691406e-05\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "n = 500\n",
    "num_iters = 10\n",
    "\n",
    "'''\n",
    "Test with TensorFlow GPU.\n",
    "'''\n",
    "start_tf = time.time()\n",
    "\n",
    "for i in range(num_iters):\n",
    "    # Tensors are defaultly placed on the GPU (CPU would be considerably slower due\n",
    "    # to the incurred communication cost).\n",
    "    # with tf.device('/CPU:0'):\n",
    "    a = tf.ones((n, n))\n",
    "    b = tf.ones((n, n))\n",
    "\n",
    "    # Run on the GPU\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "print(f'Elapsed time with TensorFlow GPU: {time.time() - start_tf}')\n",
    "\n",
    "'''\n",
    "Test with Numpy.\n",
    "'''\n",
    "start_np = time.time()\n",
    "\n",
    "# for i in range(num_iters):\n",
    "#     a = np.ones((n, n))\n",
    "#     b = np.ones((n, n))\n",
    "\n",
    "#     c = np.dot(a, b)\n",
    "\n",
    "print(f'Elapsed time with Numpy: {time.time() - start_np}') # CAN BE SLOW\n"
   ]
  },
  {
   "source": [
    "## Low Rank Phase Retrieval\n",
    "\n",
    "References:\n",
    "\n",
    "\\[1\\] Namrata Vaswani, Seyedehsara Nayer, Yonina C. Eldar. *Low Rank Phase Retrieval*. https://rutgers.box.com/s/dntl0sh157p62rgi1zerdaxrqthugr32\n",
    "\n",
    "\\[2\\] Namrata Vaswani. *Nonconvex Structured Phase Retrieval*. https://rutgers.box.com/s/x02w8frd1ep01cxdjlnojufa9npvstsz.\n",
    "\n",
    "\\[3\\] Tamara G. Kolda, Brett W. Bader. *Tensor Decompositions and Applications*. https://rutgers.box.com/s/aq9psx3mgwhms6rrzlhn94h56c3oshox. \n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Define Data Directories"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = './videos/' # directory of the test videos\n",
    "OUTPUT_DIR = './output/' # output directory\n",
    "FRAMES_DIR = './ouput/frames/' # output directory of the extracted video frames "
   ]
  },
  {
   "source": [
    "### Load the Test Video"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Directory already exists!\nDEBUG: Captured..../ouput/frames/sara/frame-0.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-1.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-2.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-3.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-4.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-5.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-6.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-7.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-8.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-9.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-10.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-11.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-12.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-13.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-14.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-15.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-16.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-17.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-18.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-19.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-20.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-21.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-22.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-23.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-24.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-25.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-26.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-27.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-28.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-29.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-30.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-31.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-32.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-33.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-34.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-35.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-36.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-37.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-38.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-39.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-40.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-41.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-42.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-43.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-44.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-45.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-46.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-47.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-48.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-49.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-50.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-51.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-52.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-53.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-54.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-55.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-56.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-57.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-58.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-59.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-60.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-61.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-62.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-63.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-64.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-65.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-66.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-67.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-68.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-69.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-70.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-71.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-72.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-73.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-74.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-75.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-76.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-77.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-78.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-79.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-80.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-81.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-82.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-83.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-84.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-85.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-86.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-87.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-88.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-89.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-90.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-91.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-92.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-93.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-94.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-95.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-96.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-97.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-98.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-99.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-100.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-101.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-102.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-103.jpg\nDEBUG: Captured..../ouput/frames/sara/frame-104.jpg\nCannot receive frame (probably end of stream). Exiting...\nApproximate rank of each frame:  3\n"
     ]
    }
   ],
   "source": [
    "# Read the video.\n",
    "video_path = INPUT_DIR + os.listdir(INPUT_DIR)[0] # define video path\n",
    "cap = cv2.VideoCapture(video_path) # read the video from path\n",
    "video_name = os.listdir(INPUT_DIR)[0].split('.')[0] # get the name of the video\n",
    "\n",
    "# Creat the folder to store the extracted frames of the video.\n",
    "try:\n",
    "    if not os.path.exists(FRAMES_DIR + video_name):\n",
    "        os.makedirs(FRAMES_DIR + video_name)\n",
    "    else:\n",
    "        print('Directory already exists!')\n",
    "except OSError:\n",
    "    print('OS ERROR')\n",
    "\n",
    "k = 0 # frame number, k = 0, 1, 2, ..., q - 1\n",
    "Xlist = []\n",
    "Rhat = 0\n",
    "while (True):\n",
    "    # Capture the video frame-by-frame.\n",
    "    # Code adopted: https://docs.opencv.org/3.4/dd/d43\n",
    "    # tutorial_py_video_display.html\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If the frame is read correctly the return boolean (ret) is true.\n",
    "    if not ret:\n",
    "        print(\"Cannot receive frame (probably end of stream). Exiting...\")\n",
    "        break\n",
    "    else:\n",
    "        # Convert the frame to grayscale.\n",
    "        gray_frame_original = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        scale = 0.025\n",
    "        width = int(gray_frame_original.shape[1] * scale)\n",
    "        height = int(gray_frame_original.shape[0] * scale)\n",
    "        gray_frame = cv2.resize(gray_frame_original, (width, height))\n",
    "        name = FRAMES_DIR + video_name + '/frame-' + str(k) + '.jpg'\n",
    "        print('DEBUG: Captured...' + name)\n",
    "        svds = np.linalg.svd(gray_frame)[1]\n",
    "        max_svd, min_svd = np.max(svds), np.min(svds)\n",
    "        normalized_svds = svds / (max_svd - min_svd)\n",
    "        Rhat += np.sum(normalized_svds > 0.1)\n",
    "        cv2.imwrite(name, gray_frame)\n",
    "        # plt.plot(range(480), normalized_svds)\n",
    "        # plt.show()\n",
    "        Xlist.append(gray_frame)\n",
    "\n",
    "        k += 1\n",
    "Rhat = Rhat // k + 1\n",
    "print('Approximate rank of each frame: ', Rhat)\n",
    "\n",
    "# Release the capture when finished.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "### Create the true signal tensor.\n",
    "\n",
    "Tensors are multi-dimensional arrays with a uniform type (`dtype`). All tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one.\n",
    "\n",
    "**Note**: In libraries like tensorflow, the rank of the tensor actually denotes the order of the tensor in our convention. We call the `rank` of a tensor in a similar manner as the rank of a matrix.\n",
    "\n",
    "The gray-scaled signal is modeled as a three-ordered tensor $\\boldsymbol{\\mathcal{X}} \\in \\mathbb{R}^{I_1 \\times I_2 \\times q}$, where $I_1 \\times I_2$ correspond to the pixel coordinates within each frame and $q$ is the total number of frames captured.\n",
    "\n",
    "**Signal Dimension**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The dimension of the true signal tensor: I1 x I2 x q: 12 x 16 x 105\nSample complexity for rank 3: O(399)\n"
     ]
    }
   ],
   "source": [
    "Xast = tf.constant(Xlist, tf.float32)\n",
    "q, I1, I2 = Xast.shape\n",
    "Xast = tf.reshape(Xast, [I1, I2, q])\n",
    "print(f'The dimension of the true signal tensor: I1 x I2 x q: {I1} x {I2} x {q}')\n",
    "print(f'Sample complexity for rank {Rhat}: O({(q + I1 + I2) * Rhat})')"
   ]
  },
  {
   "source": [
    "### Generate Phaseless Measurements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = [] # measurement tensor in list format\n",
    "m = 2000 # number of measurements\n",
    "\n",
    "np.random.seed(5) # set random seed\n",
    "\n",
    "# Generate i.i.d. measurement tensors.\n",
    "\n",
    "for j in range(m):\n",
    "    Aj = []\n",
    "    for k in range(q):\n",
    "        Ajk = np.random.randn(I1, I2) # i.i.d. normal measurement\n",
    "        Aj.append(Ajk)\n",
    "    A.append(Aj)\n",
    "\n",
    "A = tf.reshape(tf.constant(A, tf.float32), [m, I1, I2, q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate phaseless measurements.\n",
    "Y = np.zeros((m, q)) # matrix of the phaseless measurements\n",
    "\n",
    "for j in range(m):\n",
    "    for k in range(q):\n",
    "        Y[j, k] = tf.tensordot(A[j,:,:,k], Xast[:,:,k], axes=([0, 1], [0, 1]))**2\n",
    "\n",
    "Y = tf.cast(Y, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DEBUG\n\nDimension of the phaseless measurement matrix: m x q: 2000 x 105\n\nPhaseless Measurements:\n\n tf.Tensor(\n[[2.5711866e+05 3.1022844e+05 3.9392282e+06 ... 2.3886342e+06\n  2.2918038e+05 8.5250575e+05]\n [9.2204369e+05 3.8461139e+02 1.7245771e+06 ... 1.0882722e+06\n  5.4024975e+05 2.4865598e+04]\n [1.8679306e+05 1.6129268e+07 2.0637980e+06 ... 9.3982625e+05\n  9.7934941e+03 6.9455894e+05]\n ...\n [3.3589328e+05 2.4439505e+06 9.8705138e+05 ... 4.2333256e+05\n  1.4663504e+06 2.0064834e+06]\n [2.2953018e+06 1.5385001e+06 4.7616666e+05 ... 6.0902080e+06\n  1.2677964e+07 5.5812488e+05]\n [1.0500918e+06 1.9997820e+06 2.2203017e+05 ... 7.7996925e+06\n  1.5764875e+06 6.1906905e+06]], shape=(2000, 105), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('DEBUG')\n",
    "print(f'\\nDimension of the phaseless measurement matrix: m x q: {Y.shape[0]} x {Y.shape[1]}\\n')\n",
    "print('Phaseless Measurements:\\n\\n', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(I1, I2, q, R):\n",
    "    \"\"\"Initialize factor matrices.\"\"\"\n",
    "\n",
    "    U1 = tf.cast(np.random.randn(I1, R), tf.float32)\n",
    "    U2 = tf.cast(np.random.randn(I2, R), tf.float32)\n",
    "    U = [U1,U2]\n",
    "    B = tf.Variable(np.random.randn(q, R), tf.float32)\n",
    "\n",
    "    return U, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal(U, B, R, Lambda=None, type='CP'):\n",
    "    \"\"\"Construct Tensor from Kruskal Formulation.\n",
    "\n",
    "        Args:\n",
    "            U: list consisting of two factor matrices U1 (I1 x R)\n",
    "                and U2 (I2 x R) for the three-way case.\n",
    "            B: the B (q x R) factor matrix.\n",
    "            R: assumped rank (a scalar) of the low-rank tensor.\n",
    "            Lambda: normalization factors (length R).\n",
    "        \n",
    "        Returns:\n",
    "            Xhat: signal estimate (I1 x I2 x q).\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "    B = tf.cast(B, tf.float32)\n",
    "    if type == 'CP':\n",
    "        U1, U2 = U[0], U[1]\n",
    "        I1, I2, q = U1.shape[0], U2.shape[0], B.shape[0]\n",
    "        Xhat = tf.zeros([I1, I2, q])\n",
    "        if Lambda is None:\n",
    "            Lambda = tf.ones([R,])\n",
    "        for r in range(R):\n",
    "            U1U2 = tf.tensordot(U1[:, r], U2[:, r], axes=0)\n",
    "            Xhat += Lambda[r] * tf.tensordot(U1U2, B[:, r], axes=0)\n",
    "        \n",
    "        return Xhat\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DEBUG | Mean squared error for reconstruction: 3.952038696297677e-11\n"
     ]
    }
   ],
   "source": [
    "def test_kruskal():\n",
    "    from tensorly.decomposition import parafac\n",
    "\n",
    "    X = tl.tensor(np.arange(24).reshape((3, 4, 2)), dtype=tl.float32)\n",
    "    weights, factors = parafac(X, rank=3)\n",
    "\n",
    "    X_test = kruskal([factors[0], factors[1]], factors[2], 3, weights)\n",
    "\n",
    "    err = X - X_test\n",
    "\n",
    "    print(f'DEBUG | Mean squared error for reconstruction: {tf.math.reduce_sum(tf.multiply(err, err)).numpy()}')\n",
    "\n",
    "test_kruskal() # test Kruskal tensor constructor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_error(Xast, U, B, R=10):\n",
    "    err = Xast - kruskal(U, B, R)\n",
    "\n",
    "    return tf.math.reduce_sum(tf.multiply(err, err)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descent(Uhat, Bhat, A, Y, R, max_iter):\n",
    "    U1, U2 = Uhat[0], Uhat[1]\n",
    "    I1, I2 = U1.shape[0], U2.shape[0]\n",
    "    m = A.shape[0]\n",
    "    q = Bhat.shape[0]\n",
    "    Bhat = Bhat.numpy()\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        print(f'Iteration-{t}')\n",
    "        print('Computing....')\n",
    "        Xhat = kruskal(Uhat, Bhat, R)\n",
    "        Cy = np.zeros([m, q])\n",
    "        # Bhat = tf.Variable(Bhat, tf.float32)\n",
    "\n",
    "        '''\n",
    "        Update Phase.\n",
    "        '''\n",
    "        for k in range(q):\n",
    "            AX = []\n",
    "            Xk = Xhat[:,:,k]\n",
    "            for j in range(m):\n",
    "                AX.append(\n",
    "                    tf.tensordot(A[j,:,:,k], Xk, axes=([0, 1], [0, 1])))\n",
    "            Ck = tf.linalg.diag(tf.math.angle(AX))\n",
    "            Cy[:, k] = tf.tensordot(Ck, tf.math.sqrt(Y[:,k]), axes=1)\n",
    "\n",
    "        '''\n",
    "        Solve for U1.\n",
    "        '''\n",
    "        matrix = np.zeros((I1,R))\n",
    "        rhs = 0\n",
    "        for k in range(q):\n",
    "            bk = Bhat[k,:]\n",
    "            bU2_kr =  tf.multiply(U2, bk) # khatri-rao product\n",
    "            for j in range(m):\n",
    "                A1 = tl.unfold(A[j,:,:,k], 0)\n",
    "                rhs += Cy[j, k]\n",
    "                matrix += tf.linalg.matmul(A1, bU2_kr)\n",
    "        \n",
    "        matrix = tf.cast(tf.transpose(matrix), tf.float32)\n",
    "        rhs = tf.cast(rhs, tf.float32)\n",
    "        U1 = tf.linalg.lstsq(matrix, tf.linalg.diag(tf.fill((R,), rhs)))\n",
    "\n",
    "        '''\n",
    "        Solve for U2.\n",
    "        '''\n",
    "        matrix = np.zeros((I2,R))\n",
    "        rhs = 0\n",
    "        for k in range(q):\n",
    "            bk = Bhat[k,:]\n",
    "            bU1_kr =  tf.multiply(U1, bk) # khatri-rao product\n",
    "            for j in range(m):\n",
    "                A2 = tl.unfold(A[j,:,:,k], 1)\n",
    "                rhs += Cy[j, k]\n",
    "                matrix += tf.linalg.matmul(A2, bU1_kr)\n",
    "        \n",
    "        matrix = tf.cast(tf.transpose(matrix), tf.float32)\n",
    "        rhs = tf.cast(rhs, tf.float32)\n",
    "        U2 = tf.linalg.lstsq(matrix, tf.linalg.diag(tf.fill((R,), rhs)))\n",
    "\n",
    "        '''\n",
    "        Solve for bk's.\n",
    "        '''\n",
    "        vector = np.zeros((R,))\n",
    "        rhs = 0\n",
    "        for k in range(q):\n",
    "            bk = Bhat[k,:]\n",
    "            U2U1_kr =  tl.tenalg.khatri_rao([U2, U1]) # khatri-rao product\n",
    "            for j in range(m):\n",
    "                A3 = tf.reshape(A[j,:,:,k], [I1 * I2,])\n",
    "                rhs += Cy[j, k]\n",
    "                vector += tf.linalg.matvec(tf.transpose(U2U1_kr), A3)\n",
    "            vector = tf.cast(vector, tf.float32)\n",
    "            rhs = tf.cast(rhs, tf.float32)\n",
    "            Bhat[k,:] = tf.multiply(vector, 1 / rhs)\n",
    "        \n",
    "        # print(\n",
    "        #     f'Reconstruction error: {reconstruct_error([U1, U2], Bhat, R):.2f}.')\n",
    "    \n",
    "    Uhat = [U1, U2]\n",
    "    \n",
    "    return Uhat, Bhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plrpr(A, Y, R=5, max_iter=1):\n",
    "    \"\"\"Polyadic Low Rank Phase Retrieval.\n",
    "    \"\"\"\n",
    "    Uinit, Binit = initialize(I1, I2, q, R)\n",
    "    \n",
    "    Uhat, Bhat = descent(Uinit, Binit, A, Y, R, max_iter)\n",
    "\n",
    "    Xhat = kruskal(Uhat, Bhat, R)\n",
    "    \n",
    "    return Xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration-0\n",
      "Computing....\n",
      "Iteration-1\n",
      "Computing....\n",
      "Iteration-2\n",
      "Computing....\n",
      "Iteration-3\n",
      "Computing....\n",
      "Iteration-4\n",
      "Computing....\n",
      "DEBUG | Mean squared error for reconstruction: 1495695097856.0\n"
     ]
    }
   ],
   "source": [
    "def test_plrpr(A, Y, Xast, R=10, max_iter=10):\n",
    "    Xhat = plrpr(A, Y, R, max_iter)\n",
    "    filename = FRAMES_DIR + video_name + '/frame-reconstructed-' + str(k) + '.jpg'\n",
    "    cv2.imwrite(filename, Xhat[:,:,0].numpy())\n",
    "    err = Xast - Xhat\n",
    "\n",
    "    MSE = tf.math.reduce_sum(tf.multiply(err, err)).numpy()\n",
    "\n",
    "    print(f'DEBUG | Mean squared error for reconstruction: {MSE}')\n",
    "\n",
    "test_plrpr(A, Y, Xast, R = 20, max_iter = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorLRPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorUtils"
   ]
  },
  {
   "source": [
    "- Initialization (Spectral, HOSVD) for CP formulation.\n",
    "- Complex measurements.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}